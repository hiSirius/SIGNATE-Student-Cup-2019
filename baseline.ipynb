{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import catboost as ctb\n",
    "import gc\n",
    "n_compo = 10\n",
    "tsvd = TruncatedSVD(n_components=n_compo,n_iter=45)\n",
    "n_compo2 = 5\n",
    "tsvd2 = TruncatedSVD(n_components=n_compo2,n_iter=45)\n",
    "lbl = LabelEncoder()\n",
    "pd.set_option('max_column',None)\n",
    "pd.set_option('max_row',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submit.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(input_dir+\"sample_submit.csv\")\n",
    "train_data = pd.read_csv(input_dir+\"train.csv\")\n",
    "train_data = train_data[(train_data['id']!=5776)&(train_data['id']!=7492)].reset_index(drop = True)\n",
    "test_data = pd.read_csv(input_dir+\"test.csv\")\n",
    "train_data.loc[train_data['id'] == 20927,'面積'] = '43.01m2'\n",
    "test_data.loc[test_data['id'] == 39954,'間取り'] = '1R'\n",
    "cate_cols = []\n",
    "useless_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些先验的数据清洗\n",
    "# train_data.loc[train_data['id'] == 7492,'面積'] = '51.83m2'\n",
    "# train_data.loc[train_data['id'] == 5776,'賃料'] = 128000\n",
    "# train_data.loc[train_data['id'] == 20927,'面積'] = '43.01m2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train_data,test_data],axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['区'] = dataset['所在地'].apply(lambda x:x.split('区')[0]+'区')\n",
    "cate_cols += ['区']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 城镇\n",
    "def town(x):\n",
    "    tmp = x.split('区')[1].split('丁目')[0]\n",
    "    return \"\".join(list(filter(lambda x:x.isalpha(),tmp)))\n",
    "dataset['城镇'] = dataset['所在地'].apply(town)\n",
    "cate_cols += ['城镇']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无用\n",
    "# dataset['丁目'] = dataset['所在地'].apply(lambda x:x.split('区')[1].split('丁目')[0]+'丁目')\n",
    "# cate_cols += ['丁目']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无用\n",
    "# dataset['番-号'] = dataset['所在地'].apply(lambda x:np.nan if x[-1]=='目' else x.split('丁目')[-1])\n",
    "# cate_cols += ['番-号']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['区'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地铁路线\n",
    "dataset['最近路线-count'] = dataset['アクセス'].apply(lambda x:len(x.split('\\t\\t')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地铁线路\n",
    "dataset['最近地铁线路'] = dataset['アクセス'].apply(lambda x:[i.split('\\t')[0] if '\\t' in i else 'nan' for i in x.split('\\t\\t')])\n",
    "dataset['最近地铁线路'] = dataset['最近地铁线路'].apply(lambda x:\",\".join(x))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['最近地铁线路']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "tmp = pd.DataFrame(tsvd.fit_transform(tmp),columns = [str(i)+'_线路' for i in range(n_compo)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "del tmp,dataset['最近地铁线路']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地铁站\n",
    "dataset['最近地铁站'] = dataset['アクセス'].apply(lambda x:[i.split('\\t')[1] if '\\t' in i else 'nan' for i in x.split('\\t\\t')])\n",
    "dataset['最近地铁站'] = dataset['最近地铁站'].apply(lambda x:\",\".join(x))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['最近地铁站']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "tmp = pd.DataFrame(tsvd.fit_transform(tmp),columns = [str(i)+'_地铁站' for i in range(n_compo)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "del tmp,dataset['最近地铁站']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 针对地铁站做加权以及到站口的时间\n",
    "def railwayStaion(x):\n",
    "    result = []\n",
    "    for i in x.split('\\t\\t'):\n",
    "        tmp = re.findall('.*駅',i)\n",
    "        if len(tmp)!=0:\n",
    "            result.append(tmp[0])\n",
    "        else:\n",
    "            result.append(x.split('\\t')[1])\n",
    "    return result\n",
    "dataset['最近地铁站'] = dataset['アクセス'].apply(railwayStaion)\n",
    "dataset['最短时间'] = dataset['アクセス'].apply(lambda x:re.findall(r'徒歩\\d+',x))\n",
    "dataset['最短时间'] = dataset['最短时间'].apply(lambda x:[int(re.findall(r'\\d+',i)[0]) for i in x])\n",
    "dataset['min-时间'] = dataset['最短时间'].apply(lambda x:np.min(x))\n",
    "dataset['mean-时间'] = dataset['最短时间'].apply(lambda x:np.mean(x))\n",
    "dataset['max-时间'] = dataset['最短时间'].apply(lambda x:np.max(x))\n",
    "dataset['std-时间'] = dataset['最短时间'].apply(lambda x:np.std(x))\n",
    "def countStation(row):\n",
    "    station = row['最近地铁站']\n",
    "    time = row['最短时间']\n",
    "    result = []\n",
    "    for i in range(min(len(time),len(station))):\n",
    "        result.append((station[i].replace('\\t','')+\",\")*time[i])\n",
    "    return result\n",
    "dataset['最近地铁站加权'] = dataset.apply(countStation,axis = 1)\n",
    "dataset['最近地铁站加权'] = dataset['最近地铁站加权'].apply(lambda x:\"\".join(x))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['最近地铁站加权']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "tmp = pd.DataFrame(tsvd.fit_transform(tmp),columns = [str(i)+'_最近地铁站加权' for i in range(n_compo)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "del tmp,dataset['最近地铁站加权'],dataset['最近地铁站'],dataset['最短时间']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 户型\n",
    "def houseType(x):\n",
    "    # [房间,厨房,桌椅，客厅,杂物]\n",
    "    room = [0,0,0,0,0]\n",
    "    base = x.split('S')[0]\n",
    "    num = int(base[0])\n",
    "    if 'R' in base:\n",
    "        room[0]+=num\n",
    "    if 'K' in base:\n",
    "        room[1]+=num\n",
    "    if 'D' in base:\n",
    "        room[2]+=num\n",
    "    if 'L' in base:\n",
    "        room[3]+=num\n",
    "    if 'S' in base:\n",
    "        room[4]+=1\n",
    "    return room\n",
    "dataset['房间'] = dataset['間取り'].apply(houseType)\n",
    "dataset['卧室'] = dataset['房间'].apply(lambda x:x[0])\n",
    "dataset['厨房'] = dataset['房间'].apply(lambda x:x[1])\n",
    "dataset['桌椅'] = dataset['房间'].apply(lambda x:x[2])\n",
    "dataset['客厅'] = dataset['房间'].apply(lambda x:x[3])\n",
    "dataset['杂物'] = dataset['房间'].apply(lambda x:x[4])\n",
    "del dataset['房间']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建筑时间包括新建筑(新築)，目前设置为0年0月\n",
    "dataset['建筑时间-年'] = dataset['築年数'].apply(lambda x:int(x.split('年')[0]) if x !='新築' else 0)\n",
    "dataset['建筑时间-月'] = dataset['築年数'].apply(lambda x:int(x.split('年')[1].split('ヶ')[0]) if x !='新築' else 0)\n",
    "dataset['建筑时间-年月'] = dataset['建筑时间-年']*12+dataset['建筑时间-月']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols += ['方角']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['面积'] = dataset['面積'].apply(lambda x:float(x[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 层数\n",
    "def allStage(x):\n",
    "    tmp = re.findall(r'\\d+階建',x)\n",
    "    if len(tmp) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(re.findall(r'\\d+',tmp[0])[0])\n",
    "def thisStage(x):\n",
    "    tmp = re.findall(r'\\d+',x)\n",
    "    if len(tmp) == 0:\n",
    "        return np.nan\n",
    "    return int(tmp[0])\n",
    "    \n",
    "dataset['地上总层'] = dataset['所在階'].astype(str).apply(lambda x:x.replace('地下','-')).apply(allStage)\n",
    "dataset['所在层'] = dataset['所在階'].astype(str).apply(lambda x:x.replace('地下','-')).apply(thisStage)\n",
    "cate_cols += ['所在階']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62730, 15)\n"
     ]
    }
   ],
   "source": [
    "# 厕所浴室-バス・トイレ\n",
    "dataset['浴室-厕所'] = dataset['バス・トイレ'].astype(str).apply(lambda x:x.replace('／','').replace('\\t',','))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['浴室-厕所']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "print(tmp.shape)\n",
    "del tmp,dataset['浴室-厕所']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62730, 16)\n"
     ]
    }
   ],
   "source": [
    "# 厨房设备-キッチン\n",
    "def stove(x):\n",
    "    tmp = re.findall(r'ロ\\d+口',x)\n",
    "    if len(tmp) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(re.findall(r'\\d+',tmp[0])[0])\n",
    "dataset['锅灶数'] = dataset['室内設備'].astype(str).apply(stove)\n",
    "dataset['厨房设备'] = dataset['キッチン'].astype(str).apply(lambda x:x.replace('／','').replace('\\t',','))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['厨房设备']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "# tmp = pd.DataFrame(tsvd2.fit_transform(tmp),columns = [str(i)+'_厨房设备' for i in range(n_compo2)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "print(tmp.shape)\n",
    "del tmp,dataset['厨房设备']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62730, 9)\n"
     ]
    }
   ],
   "source": [
    "# 互联网通信-放送・通信\n",
    "dataset['互联网通信'] = dataset['放送・通信'].astype(str).apply(lambda x:x.replace('／','').replace('\\t',','))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['互联网通信']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "# tmp = pd.DataFrame(tsvd2.fit_transform(tmp),columns = [str(i)+'_互联网通信' for i in range(n_compo2)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "print(tmp.shape)\n",
    "del tmp,dataset['互联网通信']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62730, 43)\n"
     ]
    }
   ],
   "source": [
    "# 房间设施-室内設備\n",
    "dataset['房间设施'] = dataset['室内設備'].astype(str).apply(lambda x:x.replace('／','').replace('\\t',','))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['房间设施']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "# tmp = pd.DataFrame(tsvd2.fit_transform(tmp),columns = [str(i)+'_房间设施' for i in range(n_compo2)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "print(tmp.shape)\n",
    "del tmp,dataset['房间设施']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62730, 21)\n"
     ]
    }
   ],
   "source": [
    "# 周边环境\n",
    "dataset['周边环境'] = dataset['周辺環境'].astype(str).apply(lambda x:x.split('\\t'))\n",
    "dataset['周边环境'] = dataset['周边环境'].apply(lambda x:[i.split(' ')[0] for i in x])\n",
    "dataset['周边环境'] = dataset['周边环境'].apply(lambda x:\",\".join(x))\n",
    "countvectorizer = CountVectorizer()\n",
    "tmp = pd.DataFrame(countvectorizer.fit_transform(dataset['周边环境']).toarray(),columns = countvectorizer.get_feature_names())\n",
    "# tmp = pd.DataFrame(tsvd2.fit_transform(tmp),columns = [str(i)+'_周边环境' for i in range(n_compo2)])\n",
    "dataset = pd.concat([dataset,tmp],axis = 1)\n",
    "print(tmp.shape)\n",
    "del tmp,dataset['周边环境']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 房屋构造\n",
    "cate_cols += ['建物構造']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 契约时间\n",
    "def contract(x):\n",
    "    # return [按截止日期或者按时间，年，月，年間，月間，是否物件，是否定期借家]\n",
    "    base = [0,0,0,0,0,0,0]\n",
    "    if x == 'nan':\n",
    "        return [np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "    if '年間' in x:\n",
    "        tmp = int(re.findall(r\"\\d+年間\",x)[0].split('年間')[0])\n",
    "        base[3] += tmp\n",
    "    if 'ヶ月間' in x:\n",
    "        tmp = int(re.findall(r\"\\d+ヶ月間\",x)[0].split('ヶ月間')[0])\n",
    "        base[4] += tmp\n",
    "    if '月ま' in x:\n",
    "        tmp = int(re.findall(r\"\\d+年\",x)[0].split('年')[0])\n",
    "        base[0] = 1\n",
    "        base[1] += tmp\n",
    "        tmp = int(re.findall(r\"\\d+月\",x)[0].split('月')[0])\n",
    "        base[2] += tmp\n",
    "    if '※この物件は' in x:\n",
    "        base[-2] += 1\n",
    "    if '定期借家' in x:\n",
    "        base[-1] += 1\n",
    "    return base\n",
    "dataset['契约时间'] = dataset['契約期間'].astype(str).apply(contract)\n",
    "dataset['按截止日期或者按时间'] = dataset['契约时间'].apply(lambda x:x[0])\n",
    "dataset['年'] = dataset['契约时间'].apply(lambda x:x[1])\n",
    "dataset['月'] = dataset['契约时间'].apply(lambda x:x[2])\n",
    "dataset['年間'] = dataset['契约时间'].apply(lambda x:x[3])\n",
    "dataset['月間'] = dataset['契约时间'].apply(lambda x:x[4])\n",
    "dataset['是否物件'] = dataset['契约时间'].apply(lambda x:x[5])\n",
    "dataset['是否定期借家'] = dataset['契约时间'].apply(lambda x:x[6])\n",
    "dataset['年月間'] = dataset['年間']+12*dataset['月間']\n",
    "del dataset['契约时间']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['アクセス'] = dataset['アクセス'].astype(str).apply(lambda x:x.split('\\t\\t')[0])\n",
    "cate_cols += ['アクセス']\n",
    "# cate_cols += ['所在地']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train   5776--1203500(删除)   7492(删除)\n",
    "# test    30313\n",
    "# 做数据清洗减缓平均价格\n",
    "# dataset = dataset[(dataset['id']!=5776)&(dataset['id']!=7492)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停车场特征\n",
    "def carPark(x):\n",
    "    # [駐輪場，駐車場，バイク置き場]\n",
    "    result = [0,0,0]\n",
    "    if len(re.findall(r'駐輪場',x)) == 0:\n",
    "        result[0] = 1\n",
    "    if len(re.findall(r'駐車場',x)) == 0:\n",
    "        result[1] = 1\n",
    "    if len(re.findall(r'バイク置き場',x)) == 0:\n",
    "        result[2] = 1\n",
    "    return result\n",
    "dataset['停车场'] = dataset['駐車場'].astype(str).apply(carPark)\n",
    "dataset['駐輪場'] = dataset['停车场'].apply(lambda x:x[0]).astype(int)\n",
    "dataset['停車場'] = dataset['停车场'].apply(lambda x:x[1]).astype(int)\n",
    "dataset['バイク置き場'] = dataset['停车场'].apply(lambda x:x[2]).astype(int)\n",
    "del dataset['停车场']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停车费\n",
    "def park_fee(x):\n",
    "    tmp = re.findall(r'\\d+,\\d+円',x)\n",
    "    if len(tmp) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        tmp = tmp[0].split(',')\n",
    "        fee1 = float(tmp[0])\n",
    "        fee2 = float(tmp[1].split('円')[0])\n",
    "        return fee1*1000+fee2\n",
    "dataset['park_fee'] = dataset['駐車場'].astype(str).apply(park_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造不同小区不同层的平均价格\n",
    "    \n",
    "# train_data['所在地'] = train_data['所在地'].apply(split)\n",
    "# test_data['所在地'] = test_data['所在地'].apply(split)\n",
    "train_data['平均价格'] = train_data['賃料'] / train_data['面積'].apply(lambda x:float(x[:-2]))\n",
    "tmp = train_data.groupby(['所在地','所在階'])['平均价格'].agg({\n",
    "    'diff平均价格层层次-mean':'mean',\n",
    "    'diff平均价格层层次-min':'min',\n",
    "    'diff平均价格层层次-max':'max',\n",
    "    'diff平均价格层层次-std':'std',\n",
    "    'diff平均价格层层次-count':'count',\n",
    "})\n",
    "train_data = train_data.merge(tmp,on = ['所在地','所在階'],how = 'left')\n",
    "new_train = train_data.drop_duplicates(['所在地','所在階'])\n",
    "new_test = test_data.drop_duplicates(['所在地','所在階'])\n",
    "mean_features = new_test[['所在地','所在階']].merge(new_train[['所在地','所在階','diff平均价格层层次-mean','diff平均价格层层次-min',\n",
    "                                                        'diff平均价格层层次-max','diff平均价格层层次-std','平均价格','diff平均价格层层次-count']],\n",
    "                                              on = ['所在地','所在階'],how = 'inner')\n",
    "del mean_features['平均价格']\n",
    "tmp = train_data[['所在地','所在階','平均价格']].merge(mean_features,on = ['所在地','所在階'],how = 'inner')\n",
    "tmp['误差'] = abs(tmp['平均价格'] - tmp['diff平均价格层层次-mean'])\n",
    "tmp = tmp[tmp['误差']<=100]\n",
    "tmp.drop_duplicates(['所在地','所在階'],inplace = True)\n",
    "tmp = tmp[tmp['误差']!=0]\n",
    "\n",
    "## 这段是新添加\n",
    "# tmp2 = pd.DataFrame((tmp['所在地']+\"_\"+tmp['所在階']).value_counts(),columns = ['count'])\n",
    "# tmp2['所在地所在階'] = tmp2.index\n",
    "# tmp2 = tmp2.reset_index(drop = True)\n",
    "# tmp2 = tmp2[tmp2['count']>1]\n",
    "# tmp2.drop_duplicates(['所在地所在階'],inplace = True)\n",
    "# tmp2['所在地'] = tmp2['所在地所在階'].apply(lambda x:x.split('_')[0])\n",
    "# tmp2['所在階'] = tmp2['所在地所在階'].apply(lambda x:x.split('_')[1])\n",
    "# del tmp2['所在地所在階']\n",
    "# tmp = tmp.merge(tmp2,on = ['所在階','所在地'],how = 'right')\n",
    "# tmp.drop_duplicates(['所在地','所在階'],inplace = True)\n",
    "#####\n",
    "print(mean_features.shape)\n",
    "\n",
    "dataset = dataset.merge(tmp.drop(['平均价格','误差'],axis = 1),on = ['所在地','所在階'],how = 'left')\n",
    "# dataset = dataset.merge(mean_features,on = ['所在地','所在階'],how = 'left')\n",
    "dataset['平均估计层层次-mean-label'] = dataset['diff平均价格层层次-mean']*dataset['面积']\n",
    "dataset['平均估计层层次-min-label'] = dataset['diff平均价格层层次-min']*dataset['面积']\n",
    "dataset['平均估计层层次-max-label'] = dataset['diff平均价格层层次-max']*dataset['面积']\n",
    "\n",
    "del train_data['平均价格'],train_data['diff平均价格层层次-mean'],train_data['diff平均价格层层次-min']\n",
    "del train_data['diff平均价格层层次-max'],train_data['diff平均价格层层次-std']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = dataset[['所在地','所在階','面积','賃料']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(input_dir+\"train.csv\")\n",
    "# test_data = pd.read_csv(input_dir+\"test.csv\")\n",
    "# train_data['面积'] = train_data['面積'].apply(lambda x:float(x[:-2]))\n",
    "# test_data['面积'] = test_data['面積'].apply(lambda x:float(x[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = train_data[['所在地','所在階','面积','賃料','方角','築年数']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.sort_values(['所在地','平均价格'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.sort_values(['面积','所在地','賃料'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tmp.groupby(['面积','所在地','所在階','方角'])['賃料'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[a>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((tmp['面积'].astype(str)+tmp['所在地']+tmp['所在階']).value_counts()>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((tmp['面积'].astype(str)+tmp['所在地']+tmp['所在階']+tmp['賃料'].astype(str)).value_counts()>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cate_col in cate_cols:\n",
    "    dataset[cate_col] = lbl.fit_transform(dataset[cate_col].astype(str))\n",
    "cate_cols.remove('アクセス')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计特征\n",
    "tmp = dataset.groupby(['アクセス'])['面积'].agg({\n",
    "    'アクセス_面积_min':'min',\n",
    "    'アクセス_面积_mean':'mean',\n",
    "    'アクセス_面积_max':'max',\n",
    "    'アクセス_面积_std':'std',\n",
    "    'アクセス_count':'count',\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['アクセス'],how = 'left')\n",
    "\n",
    "tmp = dataset.groupby(['区'])['面积'].agg({\n",
    "    '区_面积_min':'min',\n",
    "    '区_面积_mean':'mean',\n",
    "    '区_面积_max':'max',\n",
    "    '区_面积_std':'std',\n",
    "    '区_count':'count',\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['区'],how = 'left')\n",
    "\n",
    "tmp = dataset.groupby(['城镇'])['面积'].agg({\n",
    "    '城镇_面积_min':'min',\n",
    "    '城镇_面积_mean':'mean',\n",
    "    '城镇_面积_max':'max',\n",
    "    '城镇_面积_std':'std',\n",
    "    '城镇_count':'count',\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['城镇'],how = 'left')\n",
    "\n",
    "tmp = dataset.groupby(['所在地','所在階'])['面积'].agg({\n",
    "    '所在地_所在階_面积_mean':'mean',\n",
    "    '所在地_所在階_面积_min':'min',\n",
    "    '所在地_所在階_面积_max':'max',\n",
    "    '所在地_所在階_面积_std':'std',\n",
    "    '所在地_所在階_面积_count':'count',\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['所在地','所在階'],how = 'left')\n",
    "\n",
    "tmp = dataset.groupby(['所在层'])['面积'].agg({\n",
    "    '所在层_面积_mean':'mean',\n",
    "    '所在层_面积_min':'min',\n",
    "    '所在层_面积_max':'max',\n",
    "    '所在层_面积_std':'std',\n",
    "    '所在层_面积_count':'count',\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['所在层'],how = 'left')\n",
    "\n",
    "tmp = dataset.groupby(['所在层'])['平均估计层层次-mean-label'].agg({\n",
    "    '所在层_平均估计层层次-label_mean':'mean',\n",
    "    '所在层_平均估计层层次-label_min':'min',\n",
    "    '所在层_平均估计层层次-label_max':'max',\n",
    "    '所在层_平均估计层层次-label_std':'std'\n",
    "})\n",
    "dataset = dataset.merge(tmp,on = ['所在层'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "useless_columns += ['id','キッチン','バス・トイレ','周辺環境','契約期間','室内設備',\n",
    "                  '放送・通信','築年数','間取り','面積','駐車場','所在地','nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dataset[~dataset['賃料'].isna()].reset_index(drop = True).drop(useless_columns,axis = 1)\n",
    "testset = dataset[dataset['賃料'].isna()].reset_index(drop = True).drop(useless_columns,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据Label做统计特征\n",
    "# tmp = trainset.groupby(['区'])['賃料'].agg({\n",
    "#     '区_money_min':'min',\n",
    "#     '区_money_mean':'mean',\n",
    "#     '区_money_max':'max',\n",
    "#     '区_money_std':'std',\n",
    "# })\n",
    "# trainset = trainset.merge(tmp,on = ['区'],how = 'left')\n",
    "# testset = testset.merge(tmp,on = ['区'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainset.drop('賃料',axis = 1)\n",
    "labels = trainset['賃料']\n",
    "test_features = testset.drop('賃料',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['平均估计层层次-mean-label'].count(),test_features['平均估计层层次-mean-label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in features.columns:\n",
    "#     sns.distplot(features[column].replace(np.nan,features[column].mean()),color = 'g')\n",
    "#     sns.distplot(test_features[column].replace(np.nan,test_features[column].mean()),color = 'r')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(features['平均估计层层次-mean-label'].replace(np.nan,-1),color = 'g')\n",
    "# sns.distplot(test_features['平均估计层层次-mean-label'].replace(np.nan,-1),color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape,labels.shape,test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 15,\n",
    "    'max_depth':-1,\n",
    "    'metric':'rmse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 全数训练\n",
    "test_pred = np.zeros([test_features.shape[0],])\n",
    "dtrain = lgb.Dataset(features,labels,\n",
    "                     categorical_feature=cate_cols\n",
    "                    )\n",
    "model_lgb = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round = 100000,\n",
    "    valid_sets = [dtrain],\n",
    "    verbose_eval = 100,\n",
    "    categorical_feature=cate_cols,\n",
    ")\n",
    "test_pred += model_lgb.predict(test_features)\n",
    "train_pred = model_lgb.predict(features)\n",
    "# Catboost\n",
    "# ctb_model = ctb.CatBoostRegressor(\n",
    "#     iterations=35000,learning_rate=0.01,max_depth=7,l2_leaf_reg=1,verbose=50,\n",
    "#     early_stopping_rounds=200,eval_metric='RMSE',task_type='GPU'\n",
    "# )\n",
    "# ctb_model.fit(features,labels,cat_features=cate_cols)\n",
    "# test_pred += ctb_model.predict(test_features)\n",
    "\n",
    "sns.distplot(labels,color = 'g')\n",
    "sns.distplot(train_pred,color ='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 五折训练\n",
    "# test_pred = np.zeros([test_features.shape[0],])\n",
    "# cv_score = []\n",
    "# kf = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "# for i,(train_idx,val_idx) in enumerate(kf.split(features,labels)):\n",
    "#     print(\"======================  fold \"+str(i+1)+\" start training=====================\")\n",
    "    \n",
    "#     ################ LGB\n",
    "#     dtrain = lgb.Dataset(features.iloc[train_idx],labels[train_idx],categorical_feature=cate_cols)\n",
    "#     dval = lgb.Dataset(features.iloc[val_idx],labels[val_idx],categorical_feature=cate_cols)\n",
    "#     model_lgb = lgb.train(\n",
    "#         params,\n",
    "#         dtrain,\n",
    "#         num_boost_round = 100000,\n",
    "#         valid_sets = [dtrain,dval],\n",
    "#         verbose_eval = 100,\n",
    "#         early_stopping_rounds = 1000,\n",
    "#         categorical_feature=cate_cols,\n",
    "#     )\n",
    "#     cv_score.append(np.sqrt(mean_squared_error(labels[val_idx],model_lgb.predict(features.iloc[val_idx]))))\n",
    "#     test_pred += model_lgb.predict(test_features)\n",
    "# print(\"Mean RMSE Score: \",np.mean(cv_score))\n",
    "# test_pred /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(input_dir+\"train.csv\")\n",
    "test_data = pd.read_csv(input_dir+\"test.csv\")\n",
    "train_data['面积'] = train_data['面積'].apply(lambda x:float(x[:-2]))\n",
    "test_data['面积'] = test_data['面積'].apply(lambda x:float(x[:-2]))\n",
    "\n",
    "train_data['城镇'] = train_data['所在地'].apply(town)\n",
    "test_data['城镇'] = test_data['所在地'].apply(town)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split('丁目')[0].split('-')[0].split('－')[0]\n",
    "train_data['所在地'] = train_data['所在地'].apply(split)\n",
    "test_data['所在地'] = test_data['所在地'].apply(split)\n",
    "train_data['所在階'] = train_data['所在階'].astype(str).apply(lambda x:x.split('建')[0])\n",
    "test_data['所在階'] = test_data['所在階'].astype(str).apply(lambda x:x.split('建')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['賃料'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些后处理\n",
    "tmp = train_data.groupby(['所在地','面积','所在階'])['賃料'].agg({\n",
    "    '房租-mean-2':'mean'\n",
    "})\n",
    "sub = sub.merge(tmp,on = ['所在地','面积','所在階'],how = 'left')\n",
    "sub['賃料'] = sub.apply(lambda row:row['賃料'] if np.isnan(row['房租-mean-2']) else row['房租-mean-2'],axis = 1)\n",
    "# sub.loc[sub['id'] ==61784,'賃料'] = 120350\n",
    "sub.loc[(sub['id'] == 55780)|(sub['id'] == 61634),'賃料'] = 1660000\n",
    "sub.loc[(sub['id'] == 34294),'賃料'] = 1800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['房租-mean-2'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','賃料']].to_csv(\"../output/baseline.csv\",index = 0,header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['賃料'].max(),labels.max(),sub['賃料'].min(),labels.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id','賃料']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = model_lgb.feature_importance()\n",
    "columns = features.columns\n",
    "feature_importance_df = pd.concat([pd.DataFrame(importance),pd.DataFrame(columns)],axis = 1)\n",
    "feature_importance_df.columns = ['importance','feature']\n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "plt.figure(figsize=(15, features.shape[1]*0.23))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (One Folds)')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
